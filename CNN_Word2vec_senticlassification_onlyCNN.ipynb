{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Word2vec_senticlassification_onlyCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayantc14/Yelp_Data_Analysis/blob/main/CNN_Word2vec_senticlassification_onlyCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo052zYFsK3e"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import re\n",
        "from wordcloud import WordCloud"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKnDHfsH-TYc",
        "outputId": "0db698fc-9a20-4eab-f244-cd1a1e875116"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "L6F5Xf1U0hyh",
        "outputId": "27e2db24-fb79-464a-cf37-ced3e2ec1ab0"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/yelp_dataset/final_data_yelp2.csv\")\n",
        "df.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-461b6d62-02e9-4324-9345-e54c2aff15eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>business_id</th>\n",
              "      <th>city</th>\n",
              "      <th>state_x</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_stars</th>\n",
              "      <th>useful_x</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>useful_y</th>\n",
              "      <th>fans</th>\n",
              "      <th>Smogscore</th>\n",
              "      <th>review_word_count</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Analysis_TextBlob</th>\n",
              "      <th>Vader Sentiment</th>\n",
              "      <th>Vader Analysis</th>\n",
              "      <th>fips</th>\n",
              "      <th>cases</th>\n",
              "      <th>deaths</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>uexKxrLmPO5iaXRT9TvWqQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>1eSNY9Csb9ajO7__ci2vTA</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Yes I am a fan    of the food  Ive tried more ...</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>251.0</td>\n",
              "      <td>0.050208</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.7723</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>b4PgITSqSWoPhyJ-Mjko7Q</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>KYCpm1B9eIIgbPatCIcVkg</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>328.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.263889</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.8519</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2EJpVjliJ6Ceijbz9HSpeQ</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>f1lLNjrLk4ETU2t_N7fHbA</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fantastic authentic Italian food  the pinsa ha...</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9307</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7m_Tj6xC5CjulQ-6Wucdpw</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>uOSQbOnLRlAuWfCSCwQFnA</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Good food very authentic The owner is pretty f...</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9169</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>DgvT9AiuePR8Z0SKV5BFvw</td>\n",
              "      <td>Portland</td>\n",
              "      <td>OR</td>\n",
              "      <td>bSTMk_GXsPE93COgqUDnMg</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The service is outstanding and the pasta is go...</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9217</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-461b6d62-02e9-4324-9345-e54c2aff15eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-461b6d62-02e9-4324-9345-e54c2aff15eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-461b6d62-02e9-4324-9345-e54c2aff15eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1             business_id  ... cases deaths label\n",
              "0           0             0  uexKxrLmPO5iaXRT9TvWqQ  ...   0.0    0.0   1.0\n",
              "1           1             1  b4PgITSqSWoPhyJ-Mjko7Q  ...   0.0    0.0   1.0\n",
              "2           2             2  2EJpVjliJ6Ceijbz9HSpeQ  ...   0.0    0.0   1.0\n",
              "3           3             3  7m_Tj6xC5CjulQ-6Wucdpw  ...   0.0    0.0   1.0\n",
              "4           4             4  DgvT9AiuePR8Z0SKV5BFvw  ...   0.0    0.0   1.0\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'business_id', 'city', 'state_x',\n",
        "       'user_id', 'review_stars', 'useful_x', 'date', 'useful_y',\n",
        "       'fans', 'Smogscore', 'review_word_count', 'Polarity',\n",
        "       'Analysis_TextBlob', 'Vader Sentiment', 'Vader Analysis', 'fips',\n",
        "       'cases', 'deaths'],axis = 1,inplace = True)"
      ],
      "metadata": {
        "id": "cfozbMFnseIy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "wohPcUB4tQur",
        "outputId": "c7909291-acd8-4703-ec42-b0f42e562102"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6a64c8c7-5c57-4a97-9eb2-0d04ec76fe0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes I am a fan    of the food  Ive tried more ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Im not a bubble tea connoisseur but Ive had it...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fantastic authentic Italian food  the pinsa ha...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Good food very authentic The owner is pretty f...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The service is outstanding and the pasta is go...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197944</th>\n",
              "      <td>I have to admit Shin Hakata Ramen was truly im...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197945</th>\n",
              "      <td>The BEST Rueben in Boston Hands down And I hav...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197946</th>\n",
              "      <td>Mike  Pattys is such a cool neighborhood gem I...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197947</th>\n",
              "      <td>Store is a little hard to find since it is hid...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197948</th>\n",
              "      <td>Food was fine drinks were good Not a typical b...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197949 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a64c8c7-5c57-4a97-9eb2-0d04ec76fe0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a64c8c7-5c57-4a97-9eb2-0d04ec76fe0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a64c8c7-5c57-4a97-9eb2-0d04ec76fe0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                     text  label\n",
              "0       Yes I am a fan    of the food  Ive tried more ...    1.0\n",
              "1       Im not a bubble tea connoisseur but Ive had it...    1.0\n",
              "2       Fantastic authentic Italian food  the pinsa ha...    1.0\n",
              "3       Good food very authentic The owner is pretty f...    1.0\n",
              "4       The service is outstanding and the pasta is go...    1.0\n",
              "...                                                   ...    ...\n",
              "197944  I have to admit Shin Hakata Ramen was truly im...    1.0\n",
              "197945  The BEST Rueben in Boston Hands down And I hav...    1.0\n",
              "197946  Mike  Pattys is such a cool neighborhood gem I...    1.0\n",
              "197947  Store is a little hard to find since it is hid...    1.0\n",
              "197948  Food was fine drinks were good Not a typical b...    1.0\n",
              "\n",
              "[197949 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bMbWaWh-x7i"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D,MaxPool1D,Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF-iqtha_lJU",
        "outputId": "b1086d1e-3f1c-457d-fe18-687dcf208da7"
      },
      "source": [
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbVK37uN-yFI"
      },
      "source": [
        "y = df[\"label\"].values\n",
        "#Converting X to format acceptable by gensim, removing annd punctuation stopwords in the process\n",
        "X = []\n",
        "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "for par in df[\"text\"].values:\n",
        "    tmp = []\n",
        "    sentences = nltk.sent_tokenize(par)\n",
        "    for sent in sentences:\n",
        "        sent = sent.lower()\n",
        "        tokens = tokenizer.tokenize(sent)\n",
        "        filtered_words = [w.strip() for w in tokens if w not in stop_words and len(w) > 1]\n",
        "        tmp.extend(filtered_words)\n",
        "    X.append(tmp)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZFAQazk_5wx"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX_FqnmpABY5"
      },
      "source": [
        "#Dimension of vectors we are generating\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "#Creating Word Vectors by Word2Vec Method \n",
        "w2v_model = gensim.models.Word2Vec(sentences=X, size=EMBEDDING_DIM, window=5, min_count=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4f27iX8AGki",
        "outputId": "d50cdd43-187f-4e99-d83e-9eb5d3f7903f"
      },
      "source": [
        "len(w2v_model.wv.vocab)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120213"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ngm9U20Adq7"
      },
      "source": [
        "# Tokenizing Text -> Repsesenting each word by a number\n",
        "# Mapping of orginal word to number is preserved in word_index property of tokenizer\n",
        "\n",
        "#Tokenized applies basic processing like changing it to lower case, explicitely setting that as False\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwZrcIh-Ad75",
        "outputId": "a0d01190-0af7-4203-e5c7-cd926a5a05a5"
      },
      "source": [
        "# lets check the first 10 words of first news\n",
        "#every word has been represented with a number\n",
        "X[0][:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[481, 416, 1, 27, 83, 545, 1130, 234, 41, 1261]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHX2bQwPAd_f",
        "outputId": "21c55757-dc46-4d1e-b629-94fa78cf1aae"
      },
      "source": [
        "#Lets check few word to numerical replesentation\n",
        "#Mapping is preserved in dictionary -> word_index property of instance\n",
        "word_index = tokenizer.word_index\n",
        "for word, num in word_index.items():\n",
        "    print(f\"{word} -> {num}\")\n",
        "    if num == 10:\n",
        "        break        "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "food -> 1\n",
            "good -> 2\n",
            "place -> 3\n",
            "great -> 4\n",
            "service -> 5\n",
            "like -> 6\n",
            "one -> 7\n",
            "time -> 8\n",
            "back -> 9\n",
            "get -> 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RrzTKUQVAeCn",
        "outputId": "afd9ec09-9d17-4183-fd2c-1045396c1b88"
      },
      "source": [
        "\n",
        "\n",
        "# Making histogram for no of words in news shows that most news article are under 200 words.\n",
        "# Lets keep each news small and truncate all news to 200 while tokenizing\n",
        "plt.hist([len(x) for x in X], bins=500)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3.000e+00, 8.000e+00, 2.500e+01, 5.600e+01, 1.470e+02, 3.450e+02,\n",
              "        9.320e+02, 2.015e+03, 3.144e+03, 3.979e+03, 4.417e+03, 4.473e+03,\n",
              "        4.494e+03, 4.424e+03, 4.449e+03, 4.475e+03, 4.264e+03, 4.199e+03,\n",
              "        4.086e+03, 4.181e+03, 4.123e+03, 3.841e+03, 3.795e+03, 3.710e+03,\n",
              "        3.666e+03, 3.641e+03, 3.635e+03, 3.411e+03, 3.316e+03, 3.171e+03,\n",
              "        3.105e+03, 3.029e+03, 2.937e+03, 2.835e+03, 2.719e+03, 2.592e+03,\n",
              "        2.592e+03, 2.559e+03, 2.372e+03, 2.342e+03, 2.229e+03, 2.216e+03,\n",
              "        2.038e+03, 2.050e+03, 1.997e+03, 1.936e+03, 1.944e+03, 1.818e+03,\n",
              "        1.699e+03, 1.728e+03, 1.712e+03, 1.597e+03, 1.538e+03, 1.478e+03,\n",
              "        1.435e+03, 1.442e+03, 1.292e+03, 1.372e+03, 1.323e+03, 1.262e+03,\n",
              "        1.240e+03, 1.246e+03, 1.195e+03, 1.149e+03, 1.060e+03, 1.067e+03,\n",
              "        1.049e+03, 1.027e+03, 9.480e+02, 9.160e+02, 8.850e+02, 8.630e+02,\n",
              "        8.880e+02, 8.450e+02, 8.560e+02, 7.470e+02, 8.070e+02, 7.790e+02,\n",
              "        7.560e+02, 6.920e+02, 6.980e+02, 6.660e+02, 6.380e+02, 6.570e+02,\n",
              "        6.070e+02, 5.970e+02, 6.360e+02, 5.510e+02, 5.660e+02, 5.420e+02,\n",
              "        5.350e+02, 5.210e+02, 5.090e+02, 4.970e+02, 5.020e+02, 4.280e+02,\n",
              "        4.720e+02, 4.130e+02, 4.130e+02, 4.080e+02, 7.150e+02, 3.790e+02,\n",
              "        3.940e+02, 3.630e+02, 3.280e+02, 3.400e+02, 3.020e+02, 3.220e+02,\n",
              "        3.180e+02, 3.170e+02, 2.930e+02, 2.860e+02, 2.900e+02, 2.510e+02,\n",
              "        2.790e+02, 2.400e+02, 2.630e+02, 2.260e+02, 2.620e+02, 2.420e+02,\n",
              "        2.220e+02, 2.080e+02, 2.070e+02, 1.930e+02, 2.050e+02, 2.120e+02,\n",
              "        1.740e+02, 1.980e+02, 1.880e+02, 1.800e+02, 1.760e+02, 1.920e+02,\n",
              "        1.830e+02, 1.740e+02, 1.560e+02, 1.590e+02, 1.560e+02, 1.410e+02,\n",
              "        1.390e+02, 1.480e+02, 1.460e+02, 1.210e+02, 1.370e+02, 1.040e+02,\n",
              "        1.390e+02, 1.250e+02, 1.000e+02, 1.140e+02, 1.040e+02, 1.230e+02,\n",
              "        1.060e+02, 1.270e+02, 1.190e+02, 8.300e+01, 9.200e+01, 9.400e+01,\n",
              "        8.600e+01, 8.300e+01, 9.100e+01, 9.600e+01, 9.800e+01, 8.100e+01,\n",
              "        8.900e+01, 9.100e+01, 8.400e+01, 6.000e+01, 8.300e+01, 7.200e+01,\n",
              "        8.900e+01, 7.100e+01, 6.300e+01, 6.100e+01, 6.200e+01, 6.700e+01,\n",
              "        5.000e+01, 5.700e+01, 5.000e+01, 7.800e+01, 6.100e+01, 5.500e+01,\n",
              "        6.100e+01, 4.200e+01, 3.900e+01, 3.900e+01, 6.300e+01, 5.600e+01,\n",
              "        4.900e+01, 3.900e+01, 3.800e+01, 4.100e+01, 3.600e+01, 4.000e+01,\n",
              "        4.800e+01, 4.500e+01, 3.400e+01, 3.600e+01, 3.400e+01, 3.000e+01,\n",
              "        3.800e+01, 3.500e+01, 8.600e+01, 3.200e+01, 2.400e+01, 3.200e+01,\n",
              "        2.200e+01, 3.300e+01, 4.100e+01, 2.500e+01, 2.600e+01, 2.600e+01,\n",
              "        2.100e+01, 2.800e+01, 3.300e+01, 2.400e+01, 2.800e+01, 1.800e+01,\n",
              "        2.600e+01, 2.700e+01, 1.800e+01, 3.000e+01, 3.000e+01, 1.700e+01,\n",
              "        3.000e+01, 1.900e+01, 2.200e+01, 2.200e+01, 2.300e+01, 2.300e+01,\n",
              "        1.100e+01, 2.200e+01, 2.000e+01, 2.300e+01, 2.000e+01, 1.600e+01,\n",
              "        1.500e+01, 2.600e+01, 1.700e+01, 1.900e+01, 1.500e+01, 2.300e+01,\n",
              "        1.300e+01, 1.200e+01, 2.600e+01, 1.000e+01, 1.200e+01, 1.200e+01,\n",
              "        7.000e+00, 6.000e+00, 2.000e+01, 1.100e+01, 1.700e+01, 1.700e+01,\n",
              "        1.700e+01, 1.300e+01, 1.100e+01, 1.700e+01, 1.300e+01, 1.200e+01,\n",
              "        1.300e+01, 1.300e+01, 1.600e+01, 8.000e+00, 9.000e+00, 8.000e+00,\n",
              "        1.000e+01, 1.000e+01, 1.100e+01, 7.000e+00, 1.300e+01, 5.000e+00,\n",
              "        1.100e+01, 9.000e+00, 7.000e+00, 3.000e+00, 1.400e+01, 4.000e+00,\n",
              "        1.100e+01, 9.000e+00, 1.000e+01, 1.000e+01, 6.000e+00, 6.000e+00,\n",
              "        7.000e+00, 5.000e+00, 9.000e+00, 1.500e+01, 1.000e+01, 8.000e+00,\n",
              "        6.000e+00, 9.000e+00, 7.000e+00, 3.000e+00, 4.000e+00, 6.000e+00,\n",
              "        7.000e+00, 6.000e+00, 4.000e+00, 4.000e+00, 3.000e+00, 5.000e+00,\n",
              "        1.000e+01, 6.000e+00, 4.000e+00, 1.000e+00, 9.000e+00, 4.000e+00,\n",
              "        2.000e+00, 6.000e+00, 4.000e+00, 7.000e+00, 6.000e+00, 5.000e+00,\n",
              "        6.000e+00, 5.000e+00, 4.000e+00, 3.000e+00, 2.000e+00, 4.000e+00,\n",
              "        3.000e+00, 7.000e+00, 3.000e+00, 6.000e+00, 5.000e+00, 3.000e+00,\n",
              "        5.000e+00, 2.000e+00, 4.000e+00, 7.000e+00, 3.000e+00, 5.000e+00,\n",
              "        2.000e+00, 3.000e+00, 1.000e+00, 3.000e+00, 4.000e+00, 3.000e+00,\n",
              "        0.000e+00, 3.000e+00, 3.000e+00, 3.000e+00, 6.000e+00, 1.000e+00,\n",
              "        3.000e+00, 2.000e+00, 2.000e+00, 1.000e+00, 5.000e+00, 1.000e+00,\n",
              "        1.000e+00, 2.000e+00, 1.000e+00, 3.000e+00, 3.000e+00, 1.000e+00,\n",
              "        6.000e+00, 2.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 3.000e+00,\n",
              "        0.000e+00, 4.000e+00, 2.000e+00, 6.000e+00, 2.000e+00, 1.000e+00,\n",
              "        0.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 0.000e+00,\n",
              "        1.000e+00, 0.000e+00, 2.000e+00, 2.000e+00, 3.000e+00, 0.000e+00,\n",
              "        2.000e+00, 5.000e+00, 1.000e+00, 2.000e+00, 2.000e+00, 1.000e+00,\n",
              "        0.000e+00, 2.000e+00, 1.000e+00, 3.000e+00, 0.000e+00, 4.000e+00,\n",
              "        0.000e+00, 5.000e+00, 0.000e+00, 1.000e+00, 2.000e+00, 0.000e+00,\n",
              "        1.000e+00, 1.000e+00, 1.000e+00, 5.000e+00, 3.000e+00, 1.000e+00,\n",
              "        0.000e+00, 3.000e+00, 1.000e+00, 3.000e+00, 2.000e+00, 1.000e+00,\n",
              "        2.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 2.000e+00,\n",
              "        2.000e+00, 0.000e+00, 2.000e+00, 2.000e+00, 2.000e+00, 6.000e+00,\n",
              "        3.000e+00, 2.000e+00, 1.000e+00, 5.000e+00, 6.000e+00, 1.000e+00,\n",
              "        2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
              "        3.000e+00, 2.000e+00, 1.000e+00, 4.000e+00, 1.000e+00, 1.000e+00,\n",
              "        1.000e+00, 5.000e+00, 2.000e+00, 2.000e+00, 2.000e+00, 2.000e+00,\n",
              "        2.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
              "        2.000e+00, 1.000e+00, 2.000e+00, 0.000e+00, 2.000e+00, 1.000e+00,\n",
              "        0.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
              "        1.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 1.000e+00]),\n",
              " array([  1.  ,   2.01,   3.02,   4.03,   5.04,   6.05,   7.06,   8.07,\n",
              "          9.08,  10.09,  11.1 ,  12.11,  13.12,  14.13,  15.14,  16.15,\n",
              "         17.16,  18.17,  19.18,  20.19,  21.2 ,  22.21,  23.22,  24.23,\n",
              "         25.24,  26.25,  27.26,  28.27,  29.28,  30.29,  31.3 ,  32.31,\n",
              "         33.32,  34.33,  35.34,  36.35,  37.36,  38.37,  39.38,  40.39,\n",
              "         41.4 ,  42.41,  43.42,  44.43,  45.44,  46.45,  47.46,  48.47,\n",
              "         49.48,  50.49,  51.5 ,  52.51,  53.52,  54.53,  55.54,  56.55,\n",
              "         57.56,  58.57,  59.58,  60.59,  61.6 ,  62.61,  63.62,  64.63,\n",
              "         65.64,  66.65,  67.66,  68.67,  69.68,  70.69,  71.7 ,  72.71,\n",
              "         73.72,  74.73,  75.74,  76.75,  77.76,  78.77,  79.78,  80.79,\n",
              "         81.8 ,  82.81,  83.82,  84.83,  85.84,  86.85,  87.86,  88.87,\n",
              "         89.88,  90.89,  91.9 ,  92.91,  93.92,  94.93,  95.94,  96.95,\n",
              "         97.96,  98.97,  99.98, 100.99, 102.  , 103.01, 104.02, 105.03,\n",
              "        106.04, 107.05, 108.06, 109.07, 110.08, 111.09, 112.1 , 113.11,\n",
              "        114.12, 115.13, 116.14, 117.15, 118.16, 119.17, 120.18, 121.19,\n",
              "        122.2 , 123.21, 124.22, 125.23, 126.24, 127.25, 128.26, 129.27,\n",
              "        130.28, 131.29, 132.3 , 133.31, 134.32, 135.33, 136.34, 137.35,\n",
              "        138.36, 139.37, 140.38, 141.39, 142.4 , 143.41, 144.42, 145.43,\n",
              "        146.44, 147.45, 148.46, 149.47, 150.48, 151.49, 152.5 , 153.51,\n",
              "        154.52, 155.53, 156.54, 157.55, 158.56, 159.57, 160.58, 161.59,\n",
              "        162.6 , 163.61, 164.62, 165.63, 166.64, 167.65, 168.66, 169.67,\n",
              "        170.68, 171.69, 172.7 , 173.71, 174.72, 175.73, 176.74, 177.75,\n",
              "        178.76, 179.77, 180.78, 181.79, 182.8 , 183.81, 184.82, 185.83,\n",
              "        186.84, 187.85, 188.86, 189.87, 190.88, 191.89, 192.9 , 193.91,\n",
              "        194.92, 195.93, 196.94, 197.95, 198.96, 199.97, 200.98, 201.99,\n",
              "        203.  , 204.01, 205.02, 206.03, 207.04, 208.05, 209.06, 210.07,\n",
              "        211.08, 212.09, 213.1 , 214.11, 215.12, 216.13, 217.14, 218.15,\n",
              "        219.16, 220.17, 221.18, 222.19, 223.2 , 224.21, 225.22, 226.23,\n",
              "        227.24, 228.25, 229.26, 230.27, 231.28, 232.29, 233.3 , 234.31,\n",
              "        235.32, 236.33, 237.34, 238.35, 239.36, 240.37, 241.38, 242.39,\n",
              "        243.4 , 244.41, 245.42, 246.43, 247.44, 248.45, 249.46, 250.47,\n",
              "        251.48, 252.49, 253.5 , 254.51, 255.52, 256.53, 257.54, 258.55,\n",
              "        259.56, 260.57, 261.58, 262.59, 263.6 , 264.61, 265.62, 266.63,\n",
              "        267.64, 268.65, 269.66, 270.67, 271.68, 272.69, 273.7 , 274.71,\n",
              "        275.72, 276.73, 277.74, 278.75, 279.76, 280.77, 281.78, 282.79,\n",
              "        283.8 , 284.81, 285.82, 286.83, 287.84, 288.85, 289.86, 290.87,\n",
              "        291.88, 292.89, 293.9 , 294.91, 295.92, 296.93, 297.94, 298.95,\n",
              "        299.96, 300.97, 301.98, 302.99, 304.  , 305.01, 306.02, 307.03,\n",
              "        308.04, 309.05, 310.06, 311.07, 312.08, 313.09, 314.1 , 315.11,\n",
              "        316.12, 317.13, 318.14, 319.15, 320.16, 321.17, 322.18, 323.19,\n",
              "        324.2 , 325.21, 326.22, 327.23, 328.24, 329.25, 330.26, 331.27,\n",
              "        332.28, 333.29, 334.3 , 335.31, 336.32, 337.33, 338.34, 339.35,\n",
              "        340.36, 341.37, 342.38, 343.39, 344.4 , 345.41, 346.42, 347.43,\n",
              "        348.44, 349.45, 350.46, 351.47, 352.48, 353.49, 354.5 , 355.51,\n",
              "        356.52, 357.53, 358.54, 359.55, 360.56, 361.57, 362.58, 363.59,\n",
              "        364.6 , 365.61, 366.62, 367.63, 368.64, 369.65, 370.66, 371.67,\n",
              "        372.68, 373.69, 374.7 , 375.71, 376.72, 377.73, 378.74, 379.75,\n",
              "        380.76, 381.77, 382.78, 383.79, 384.8 , 385.81, 386.82, 387.83,\n",
              "        388.84, 389.85, 390.86, 391.87, 392.88, 393.89, 394.9 , 395.91,\n",
              "        396.92, 397.93, 398.94, 399.95, 400.96, 401.97, 402.98, 403.99,\n",
              "        405.  , 406.01, 407.02, 408.03, 409.04, 410.05, 411.06, 412.07,\n",
              "        413.08, 414.09, 415.1 , 416.11, 417.12, 418.13, 419.14, 420.15,\n",
              "        421.16, 422.17, 423.18, 424.19, 425.2 , 426.21, 427.22, 428.23,\n",
              "        429.24, 430.25, 431.26, 432.27, 433.28, 434.29, 435.3 , 436.31,\n",
              "        437.32, 438.33, 439.34, 440.35, 441.36, 442.37, 443.38, 444.39,\n",
              "        445.4 , 446.41, 447.42, 448.43, 449.44, 450.45, 451.46, 452.47,\n",
              "        453.48, 454.49, 455.5 , 456.51, 457.52, 458.53, 459.54, 460.55,\n",
              "        461.56, 462.57, 463.58, 464.59, 465.6 , 466.61, 467.62, 468.63,\n",
              "        469.64, 470.65, 471.66, 472.67, 473.68, 474.69, 475.7 , 476.71,\n",
              "        477.72, 478.73, 479.74, 480.75, 481.76, 482.77, 483.78, 484.79,\n",
              "        485.8 , 486.81, 487.82, 488.83, 489.84, 490.85, 491.86, 492.87,\n",
              "        493.88, 494.89, 495.9 , 496.91, 497.92, 498.93, 499.94, 500.95,\n",
              "        501.96, 502.97, 503.98, 504.99, 506.  ]),\n",
              " <a list of 500 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIWl4wEJAzL9",
        "outputId": "a7258353-cc9a-4ade-ecbd-eb0e4ab15ebf"
      },
      "source": [
        "nos = np.array([len(x) for x in X])\n",
        "len(nos[nos  < 700])\n",
        "# Out of 48k news, 44k have less than 700 words"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "197949"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B10mXzcGAzPs"
      },
      "source": [
        "#Lets keep all reviews to 700(or 200), add padding to news with less than 200 words and truncating long ones\n",
        "maxlen = 700 \n",
        "\n",
        "#Making all news of size maxlen defined above\n",
        "X = pad_sequences(X, maxlen=maxlen)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mbGFf5zAzWC"
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "# Embedding Layer creates one more vector for \"UNKNOWN\" words, or padded words (0s). This Vector is filled with zeros.\n",
        "# Thus our vocab size inceeases by 1\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf5uYoP_BNqe"
      },
      "source": [
        "# Function to create weight matrix from word2vec gensim model\n",
        "def get_weight_matrix(model, vocab):\n",
        "    # total vocabulary size plus 0 for unknown words\n",
        "    vocab_size = len(vocab) + 1\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
        "    for word, i in vocab.items():\n",
        "        weight_matrix[i] = model[word]\n",
        "    return weight_matrix"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05QVZ6Z4BNur"
      },
      "source": [
        "#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
        "embedding_vectors = get_weight_matrix(w2v_model, word_index)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j5KM7l5NqXJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCb6A55vBU5E"
      },
      "source": [
        "#Defining Neural Network\n",
        "model = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=maxlen, trainable=False))\n",
        "#LSTM \n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPool1D(pool_size=2))\n",
        "#model.add(LSTM(units=128))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9gRhfRuBU77",
        "outputId": "56db78de-adc2-45e3-87a0-515d7c8cf1ca"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 700, 100)          12021400  \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 700, 32)           9632      \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 350, 32)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 350, 128)          4224      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 44800)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 44801     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,080,057\n",
            "Trainable params: 58,657\n",
            "Non-trainable params: 12,021,400\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udWd7ArJBU_r"
      },
      "source": [
        "#Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y) \n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnyM9R4BBkbz",
        "outputId": "7c505c4f-3c5a-443f-cd3c-f29acba97c77"
      },
      "source": [
        "model.fit(X_train, y_train, validation_split=0.3, epochs=6)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "3248/3248 [==============================] - 38s 11ms/step - loss: 0.1581 - acc: 0.9340 - val_loss: 0.1431 - val_acc: 0.9407\n",
            "Epoch 2/6\n",
            "3248/3248 [==============================] - 32s 10ms/step - loss: 0.1315 - acc: 0.9450 - val_loss: 0.1395 - val_acc: 0.9437\n",
            "Epoch 3/6\n",
            "3248/3248 [==============================] - 33s 10ms/step - loss: 0.1183 - acc: 0.9506 - val_loss: 0.1410 - val_acc: 0.9437\n",
            "Epoch 4/6\n",
            "3248/3248 [==============================] - 32s 10ms/step - loss: 0.1061 - acc: 0.9559 - val_loss: 0.1490 - val_acc: 0.9418\n",
            "Epoch 5/6\n",
            "3248/3248 [==============================] - 32s 10ms/step - loss: 0.0940 - acc: 0.9618 - val_loss: 0.1781 - val_acc: 0.9396\n",
            "Epoch 6/6\n",
            "3248/3248 [==============================] - 37s 11ms/step - loss: 0.0837 - acc: 0.9659 - val_loss: 0.1738 - val_acc: 0.9359\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29080bdc90>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_pMSAeoBkgj"
      },
      "source": [
        "#Prediction is in probability of news being real, so converting into classes\n",
        "# Class 0 (Fake) if predicted prob < 0.5, else class 1 (Real)\n",
        "y_pred = (model.predict(X_test) >= 0.5).astype(\"int\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu_5ADuJByTO",
        "outputId": "b36ca03c-cff2-4193-cf31-c2e166a85615"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9379849660523764"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQzUYekcByyS",
        "outputId": "20b2deb7-46f8-4349-c0c0-54654e4b3150"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.72      0.70      4960\n",
            "         1.0       0.97      0.96      0.97     44528\n",
            "\n",
            "    accuracy                           0.94     49488\n",
            "   macro avg       0.82      0.84      0.83     49488\n",
            "weighted avg       0.94      0.94      0.94     49488\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfldqaEN1iRi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}